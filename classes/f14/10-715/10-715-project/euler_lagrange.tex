\documentclass{article}
\usepackage{amsmath, amsfonts, amsthm, amssymb}
\usepackage{fullpage}

% For figures
\usepackage{graphicx}
\usepackage{subfigure}

\usepackage{amsmath,amssymb}

\usepackage{hyperref}

%%%%%%%%%%%%%%%%%%%%CONTENT MACROS%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\qed}{\quad \ensuremath{\blacksquare}}    % QED blacksquare
\newcommand{\inv}{^{-1}}                            % inverse operator
\newcommand{\sminus}{\backslash}                    % set minus
\newcommand{\N}{\mathbb{N}}                         % natural numbers
\newcommand{\R}{\mathbb{R}}                         % real numbers
\newcommand{\pow}{\mathcal{P}}                      % power set
\newcommand{\Se}{\mathcal{S}}                       % partition
\newcommand{\D}{\mathcal{D}}                        % partition
\newcommand{\e}{\varepsilon}                        % \varepsilon
\renewcommand{\d}{\delta}                           % \delta
\newcommand{\X}{\mathcal{X}}                        % X domain
\newcommand{\Y}{\mathcal{Y}}                        % Y domain
\newcommand{\Z}{\mathcal{Z}}                        % Z domain
\newcommand{\A}{\mathcal{A}}                        % sub-domain
\newcommand{\E}{\mathbb{E}}                         % expected value
\newcommand{\V}{\mathbb{V}}                         % variance
\newcommand{\pr}{\mathbb{P}}                        % probability
\newcommand{\hP}{{\hat P}}                          % 
\newcommand{\cpest}{\widehat{p}_h}                  % clipped estimated p_n
\newcommand{\cqest}{\widehat{q}_h}                  % clipped estimated q_n
\newcommand{\pest}{\widetilde{p}_h}                 % estimated p_n
\newcommand{\qest}{\widetilde{q}_h}                 % estimated q_n
\newcommand{\dist}{\operatorname{dist}}             % distance operator
\newcommand{\acro}[1]{\textsc{\MakeLowercase{#1}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{natbib}
\usepackage[disable]{todonotes}

\begin{document}
\begin{center}
{\bf\Large Manifold Learning via Conditional Entropy Minimization:\\
Euler-Lagrange Derivation}\\
Shashank Singh\\
sss1@andrew.cmu.edu\\
\end{center}

\section{Introduction}

$f(x_1) = 0,f(x_n) = 1$.

$L(t,x,v) = \hat p(t,x) \left( \log p(t,x) - p(t) \right)$
(or $L(t,x,v) = L(t,v)$ to get properties of CDF?)

%{\small
%\bibliography{biblio}
%%\bibliographystyle{icml2014}
%\bibliographystyle{plain}
%}
\end{document}
